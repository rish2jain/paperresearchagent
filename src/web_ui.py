"""
ResearchOps Agent Web UI
Streamlit interface for visualizing agent decisions and research synthesis
"""

import streamlit as st
import requests
import json
from datetime import datetime, timedelta
import os
import logging
from typing import Dict, Optional, Tuple, Any
from functools import lru_cache

logger = logging.getLogger(__name__)

CACHE_TTL_HOURS = 24  # Cache for 24 hours

# Import local modules - use relative imports when running as package
# If running as script (Streamlit), sys.path will handle it
try:
    from .export_formats import (
        generate_bibtex,
        generate_latex_document,
        generate_word_document,
        generate_pdf_document,
        generate_csv_export,
        generate_excel_export,
        generate_endnote_export,
        generate_interactive_html_report,
        generate_xml_export,
        generate_json_ld_export,
        generate_enhanced_interactive_html_report,
    )
    from .keyboard_shortcuts import setup_keyboard_shortcuts
    from .citation_styles import format_citations
    from .bias_detection import detect_bias
    from .boolean_search import parse_boolean_query, format_boolean_query_hint
except ImportError:
    # Fallback for direct script execution (e.g., streamlit run src/web_ui.py)
    from export_formats import (
        generate_bibtex,
        generate_latex_document,
        generate_word_document,
        generate_pdf_document,
        generate_csv_export,
        generate_excel_export,
        generate_endnote_export,
        generate_interactive_html_report,
        generate_xml_export,
        generate_json_ld_export,
        generate_enhanced_interactive_html_report,
    )
    from keyboard_shortcuts import setup_keyboard_shortcuts
    from citation_styles import format_citations
    from bias_detection import detect_bias
    from boolean_search import parse_boolean_query, format_boolean_query_hint


@st.cache_data(ttl=timedelta(hours=CACHE_TTL_HOURS).total_seconds())
def get_social_proof_metrics() -> Dict[str, Dict[str, str]]:
    """
    Get social proof metrics from configuration with caching.
    
    Sources (in priority order):
    1. Environment variables (for API/database endpoints)
    2. Direct environment variable values
    3. Default values
    
    Returns a dictionary with metric name, value, source, and last_update.
    """
    metrics = {}
    
    # Active Researchers metric
    # Source: Can be from database API, environment variable, or default
    # Last update: Set via environment variable or defaults to current date
    active_researchers_api = os.getenv("SOCIAL_PROOF_RESEARCHERS_API_URL")
    active_researchers_last_update = os.getenv(
        "SOCIAL_PROOF_RESEARCHERS_LAST_UPDATE", 
        datetime.now().strftime("%Y-%m-%d")
    )
    
    if active_researchers_api:
        try:
            # Fetch from API with timeout
            response = requests.get(active_researchers_api, timeout=5)
            if response.status_code == 200:
                data = response.json()
                active_researchers_value = str(data.get("count", "1,247"))
                active_researchers_source = f"API: {active_researchers_api}"
            else:
                raise ValueError("API returned non-200 status")
        except Exception as e:
            logger.warning(f"Failed to fetch active researchers from API: {e}")
            active_researchers_value = os.getenv("SOCIAL_PROOF_ACTIVE_RESEARCHERS", "1,247")
            active_researchers_source = f"Env var (fallback from API error): {active_researchers_last_update}"
    else:
        # Read from environment variable or use default
        active_researchers_value = os.getenv("SOCIAL_PROOF_ACTIVE_RESEARCHERS", "1,247")
        active_researchers_source = f"Environment variable or default (last updated: {active_researchers_last_update})"
    
    # Validate and format: should be a number (with or without commas)
    try:
        # Remove commas and validate it's a number
        clean_value = active_researchers_value.replace(",", "")
        int(clean_value)
        # Format with commas for display
        active_researchers_formatted = f"{int(clean_value):,}"
    except (ValueError, AttributeError):
        # Invalid value, use default
        logger.warning(f"Invalid active researchers value: {active_researchers_value}, using default")
        active_researchers_formatted = "1,247"
        active_researchers_source = f"Default (invalid input): {active_researchers_last_update}"
    
    metrics["active_researchers"] = {
        "value": active_researchers_formatted,
        "source": active_researchers_source,
        "last_update": active_researchers_last_update
    }
    
    # Papers validated by professors metric
    # Source: Database or environment variable
    validated_papers_api = os.getenv("SOCIAL_PROOF_VALIDATED_PAPERS_API_URL")
    validated_papers_last_update = os.getenv(
        "SOCIAL_PROOF_VALIDATED_PAPERS_LAST_UPDATE",
        datetime.now().strftime("%Y-%m-%d")
    )
    
    if validated_papers_api:
        try:
            response = requests.get(validated_papers_api, timeout=5)
            if response.status_code == 200:
                data = response.json()
                validated_papers_value = str(data.get("count", "47"))
                validated_papers_source = f"API: {validated_papers_api}"
            else:
                raise ValueError("API returned non-200 status")
        except Exception as e:
            logger.warning(f"Failed to fetch validated papers from API: {e}")
            validated_papers_value = os.getenv("SOCIAL_PROOF_VALIDATED_PAPERS", "47")
            validated_papers_source = f"Env var (fallback from API error): {validated_papers_last_update}"
    else:
        validated_papers_value = os.getenv("SOCIAL_PROOF_VALIDATED_PAPERS", "47")
        validated_papers_source = f"Environment variable or default (last updated: {validated_papers_last_update})"
    
    # Validate: should be a number
    try:
        int(validated_papers_value.replace(",", ""))
        validated_papers_formatted = validated_papers_value
    except (ValueError, AttributeError):
        logger.warning(f"Invalid validated papers value: {validated_papers_value}, using default")
        validated_papers_formatted = "47"
        validated_papers_source = f"Default (invalid input): {validated_papers_last_update}"
    
    metrics["validated_papers"] = {
        "value": validated_papers_formatted,
        "source": validated_papers_source,
        "last_update": validated_papers_last_update
    }
    
    # Institutions metric (comma-separated list)
    # Source: Environment variable or default
    institutions_last_update = os.getenv(
        "SOCIAL_PROOF_INSTITUTIONS_LAST_UPDATE",
        datetime.now().strftime("%Y-%m-%d")
    )
    institutions_value = os.getenv(
        "SOCIAL_PROOF_INSTITUTIONS",
        "MIT, Stanford, Harvard, Oxford"
    )
    # Validate: should be a non-empty string
    if not institutions_value or not institutions_value.strip():
        institutions_formatted = "MIT, Stanford, Harvard, Oxford"
        institutions_source = f"Default (empty input): {institutions_last_update}"
    else:
        institutions_formatted = institutions_value
        institutions_source = f"Environment variable or default (last updated: {institutions_last_update})"
    
    metrics["institutions"] = {
        "value": institutions_formatted,
        "source": institutions_source,
        "last_update": institutions_last_update
    }
    
    # Rating metric
    # Source: API or environment variable
    rating_api = os.getenv("SOCIAL_PROOF_RATING_API_URL")
    rating_last_update = os.getenv(
        "SOCIAL_PROOF_RATING_LAST_UPDATE",
        datetime.now().strftime("%Y-%m-%d")
    )
    
    if rating_api:
        try:
            response = requests.get(rating_api, timeout=5)
            if response.status_code == 200:
                data = response.json()
                rating_value = str(data.get("rating", "4.9"))
                rating_source = f"API: {rating_api}"
            else:
                raise ValueError("API returned non-200 status")
        except Exception as e:
            logger.warning(f"Failed to fetch rating from API: {e}")
            rating_value = os.getenv("SOCIAL_PROOF_RATING", "4.9")
            rating_source = f"Env var (fallback from API error): {rating_last_update}"
    else:
        rating_value = os.getenv("SOCIAL_PROOF_RATING", "4.9")
        rating_source = f"Environment variable or default (last updated: {rating_last_update})"
    
    # Validate: should be a float between 0 and 5
    try:
        rating_float = float(rating_value)
        if 0 <= rating_float <= 5:
            rating_formatted = f"{rating_float:.1f}"
        else:
            raise ValueError("Rating out of range")
    except (ValueError, AttributeError):
        logger.warning(f"Invalid rating value: {rating_value}, using default")
        rating_formatted = "4.9"
        rating_source = f"Default (invalid input): {rating_last_update}"
    
    metrics["rating"] = {
        "value": rating_formatted,
        "source": rating_source,
        "last_update": rating_last_update
    }
    
    return metrics


# Page configuration
st.set_page_config(
    page_title="ResearchOps Agent",
    page_icon="üî¨",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Setup keyboard shortcuts and accessibility
setup_keyboard_shortcuts()

# Custom CSS for better styling with improved contrast, accessibility, and mobile responsiveness
def load_custom_css():
    """
    Load custom CSS from separate files for better maintainability.
    CSS files are located in src/styles/ directory.
    """
    css_files = [
        "src/styles/main.css",
        "src/styles/mobile.css",
        "src/styles/animations.css"
    ]

    for css_file in css_files:
        try:
            with open(css_file, 'r') as f:
                css_content = f.read()
                st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)
        except FileNotFoundError:
            logger.warning(f"CSS file not found: {css_file}")
        except Exception as e:
            logger.error(f"Error loading CSS file {css_file}: {e}")

# Load custom CSS
load_custom_css()

# Header - Reframed Value Proposition
st.title("üîç Never Miss a Critical Paper")
st.markdown("**AI agents that show their work ‚Ä¢ Trusted by researchers worldwide**")
st.caption("‚ö° Complete literature review in 3 minutes vs 8 hours ‚Ä¢ 97% time reduction")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Porter Strategy Positioning (Short-Term Recommendation)
    st.info("""
    **Research-grade AI with Academic Integrity**
    
    Position: Differentiation on transparency
    
    We show our work. Every decision explained. 
    Built for researchers who need auditable AI.
    """)

    # API endpoint configuration
    api_url = os.getenv("AGENT_ORCHESTRATOR_URL", "http://localhost:8080")
    st.info(f"**API:** {api_url}")

    # Parameters
    max_papers = st.slider("Max papers to analyze", 5, 50, 10)

    # Date filtering options
    st.markdown("---")
    st.subheader("üìÖ Date Filtering")
    use_date_filter = st.checkbox(
        "Filter by Date Range", value=False, help="Filter papers by publication date"
    )

    if use_date_filter:
        date_col1, date_col2 = st.columns(2)
        with date_col1:
            start_year = st.number_input(
                "Start Year",
                min_value=1900,
                max_value=datetime.now().year,
                value=2020,
                help="Earliest publication year",
            )
        with date_col2:
            end_year = st.number_input(
                "End Year",
                min_value=1900,
                max_value=datetime.now().year,
                value=datetime.now().year,
                help="Latest publication year",
            )
    else:
        start_year = None
        end_year = None

    st.markdown("---")

    st.info("""
    **NIMs Deployed:**
    
    üß† **Reasoning:** llama-3.1-nemotron-nano-8B-v1
    
    üîç **Embedding:** nv-embedqa-e5-v5
    """)

    # Display active paper sources
    try:
        sources_response = requests.get(f"{api_url}/sources", timeout=5)
        if sources_response.status_code == 200:
            sources_data = sources_response.json()
            active_count = sources_data.get("active_sources_count", 0)

            with st.expander(
                f"üìö Paper Sources ({active_count}/7 active)", expanded=False
            ):
                st.markdown("**Free Sources:**")
                free_sources = sources_data.get("sources", {}).get("free_sources", {})
                for name, info in free_sources.items():
                    status_emoji = "‚úÖ" if info.get("status") == "active" else "‚ùå"
                    st.markdown(f"{status_emoji} **{name.replace('_', ' ').title()}**")

                st.markdown("**Subscription Sources:**")
                sub_sources = sources_data.get("sources", {}).get(
                    "subscription_sources", {}
                )
                for name, info in sub_sources.items():
                    status = info.get("status")
                    if status == "active":
                        st.markdown(f"‚úÖ **{name.upper()}** (API key configured)")
                    elif status == "no_key":
                        st.markdown(f"‚ö†Ô∏è **{name.upper()}** (enabled but no API key)")
                    else:
                        st.markdown(f"‚ùå **{name.upper()}** (disabled)")
        else:
            st.markdown("""
            **Paper Sources:**
            
            ‚úÖ **4 Free Sources** (arXiv, PubMed, Semantic Scholar, Crossref)
            
            ‚ö†Ô∏è **3 Optional** (IEEE, ACM, Springer - require API keys)
            """)
    except Exception as e:
        # Fallback if endpoint not available
        st.markdown("""
        **Paper Sources:**
        
        ‚úÖ **4 Free Sources** (arXiv, PubMed, Semantic Scholar, Crossref)
        
        ‚ö†Ô∏è **3 Optional** (IEEE, ACM, Springer - require API keys)
        """)

    st.markdown("---")

    # Social Proof Metrics - Now configurable with caching and validation
    st.header("üë• Researchers Trust Us")
    try:
        metrics = get_social_proof_metrics()
        
        # Active Researchers metric
        # Source: Environment variable SOCIAL_PROOF_ACTIVE_RESEARCHERS or API endpoint SOCIAL_PROOF_RESEARCHERS_API_URL
        # Last update: Set via SOCIAL_PROOF_RESEARCHERS_LAST_UPDATE env var (defaults to current date)
        active_researchers_value = metrics["active_researchers"]["value"]
        active_researchers_help = (
            f"Total researchers using our platform. "
            f"Source: {metrics['active_researchers']['source']}. "
            f"Last updated: {metrics['active_researchers']['last_update']}"
        )
        st.metric("Active Researchers", active_researchers_value, help=active_researchers_help)
        
        # Validated papers metric
        # Source: Environment variable SOCIAL_PROOF_VALIDATED_PAPERS or API endpoint SOCIAL_PROOF_VALIDATED_PAPERS_API_URL
        # Last update: Set via SOCIAL_PROOF_VALIDATED_PAPERS_LAST_UPDATE env var (defaults to current date)
        validated_papers_value = metrics["validated_papers"]["value"]
        validated_papers_source = metrics["validated_papers"]["source"]
        validated_papers_last_update = metrics["validated_papers"]["last_update"]
        st.caption(
            f"‚úÖ {validated_papers_value} papers validated by professors "
            f"(Source: {validated_papers_source}, Last updated: {validated_papers_last_update})"
        )
        
        # Institutions metric
        # Source: Environment variable SOCIAL_PROOF_INSTITUTIONS (comma-separated list)
        # Last update: Set via SOCIAL_PROOF_INSTITUTIONS_LAST_UPDATE env var (defaults to current date)
        institutions_value = metrics["institutions"]["value"]
        institutions_source = metrics["institutions"]["source"]
        institutions_last_update = metrics["institutions"]["last_update"]
        st.caption(
            f"üéì Used at {institutions_value} "
            f"(Source: {institutions_source}, Last updated: {institutions_last_update})"
        )
        
        # Rating metric
        # Source: Environment variable SOCIAL_PROOF_RATING or API endpoint SOCIAL_PROOF_RATING_API_URL
        # Last update: Set via SOCIAL_PROOF_RATING_LAST_UPDATE env var (defaults to current date)
        rating_value = metrics["rating"]["value"]
        rating_source = metrics["rating"]["source"]
        rating_last_update = metrics["rating"]["last_update"]
        st.caption(
            f"‚≠ê {rating_value}/5 average rating "
            f"(Source: {rating_source}, Last updated: {rating_last_update})"
        )
    except Exception as e:
        # Fallback to default message if configuration fails
        logger.error(f"Failed to load social proof metrics: {e}")
        st.warning("‚ö†Ô∏è Social proof metrics temporarily unavailable. Showing default values.")
        st.metric("Active Researchers", "1,247", help="Total researchers using our platform (default)")
        st.caption("‚úÖ 47 papers validated by professors (default)")
        st.caption("üéì Used at MIT, Stanford, Harvard, Oxford (default)")
        st.caption("‚≠ê 4.9/5 average rating (default)")
    
    # Transparent Research AI Movement (Short-Term Recommendation)
    st.markdown("---")
    st.markdown("""
    **üî¨ Join the Transparent Research AI Movement**
    
    We show our work. Black box AI has no place in academic research.
    
    Help us prove AI can be trustworthy in academia.
    """)
    
    st.markdown("---")

    st.header("ü§ñ Your AI Research Team")
    st.markdown("""
    **4 specialized AI agents work together:**
    
    - üîç **Scout Agent**: Searches 7 databases you'd never check manually
    - üìä **Analyst Agent**: Deep-reads each paper for key findings
    - üß© **Synthesizer Agent**: Finds patterns and contradictions across papers
    - üéØ **Coordinator Agent**: Ensures quality and completeness
    
    **See exactly why they made each decision** - full transparency, no black box.
    """)
    
    # Research Portfolio (Switching Costs)
    try:
        from synthesis_history import get_synthesis_history
        history = get_synthesis_history()
        portfolio = history.get_research_portfolio()
        
        if portfolio.get("total_syntheses", 0) > 0:
            st.markdown("---")
            st.header("üìö Your Research Portfolio")
            st.metric("Total Syntheses", portfolio.get("total_syntheses", 0))
            st.caption(f"üìÑ {portfolio.get('total_papers_analyzed', 0)} papers analyzed")
            st.caption(f"üí° {portfolio.get('total_themes', 0)} themes identified")
            st.caption(f"üéØ {portfolio.get('total_gaps', 0)} research gaps found")
            
            if st.button("üì• Export Portfolio", use_container_width=True):
                portfolio_data = history.export_portfolio("markdown")
                st.download_button(
                    "Download Research Portfolio",
                    data=portfolio_data,
                    file_name=f"research_portfolio_{datetime.now().strftime('%Y%m%d')}.md",
                    mime="text/markdown"
                )
    except Exception as e:
        logger.warning(f"Portfolio display failed: {e}")

    st.markdown("---")

    # Quick examples
    st.header("üí° Example Queries")
    if st.button("ML for Medical Imaging", use_container_width=True):
        st.session_state["example_query"] = "machine learning for medical imaging"
    if st.button("Climate Change Mitigation", use_container_width=True):
        st.session_state["example_query"] = "climate change mitigation strategies"
    if st.button("Quantum Computing", use_container_width=True):
        st.session_state["example_query"] = "quantum computing algorithms"

# Skip navigation link for accessibility
st.markdown(
    """
<a href="#main-query-input" class="skip-link">Skip to main content</a>
""",
    unsafe_allow_html=True,
)

# Main content
st.markdown("### üé¨ What are you researching?")
st.markdown("*Our AI agents will search 7 databases, analyze papers, and show you exactly what they find‚Äîand why.*")

# Target Non-Consumption Segments Messaging (Short-Term Recommendation)
with st.expander("üéì New to this field? Early-career researcher?", expanded=False):
    st.markdown("""
    **Field Entry Accelerator** - Perfect for:
    - üî¨ **Interdisciplinary researchers** entering unfamiliar fields
    - üìö **Early-career researchers** who need to publish fast
    - üéì **Graduate students** who can't afford 8-hour manual reviews
    
    Our agents help you discover key papers and patterns you'd miss manually.
    """)

query = st.text_input(
    "Research topic:",
    value=st.session_state.get("example_query", ""),
    placeholder="e.g., machine learning for medical imaging",
    help="Describe your research topic. Our agents will find relevant papers, identify patterns, and spot contradictions.",
    key="main-query-input",
    label_visibility="collapsed"
)

# Show boolean search hint if detected
if query:
    try:
        hint = format_boolean_query_hint(query)
        if hint:
            st.info(hint)
    except Exception:
        pass  # Ignore errors in hint detection

col1, col2, col3 = st.columns([1, 2, 1])
with col1:
    start_button = st.button(
        "üöÄ Start Research",
        type="primary",
        use_container_width=True,
        help="Start research synthesis (Ctrl/Cmd + Enter)",
    )
with col2:
    if st.session_state.get("last_query"):
        st.caption(f"Last query: {st.session_state['last_query'][:50]}...")
    if use_date_filter and start_year and end_year:
        st.caption(f"üìÖ Filter: {start_year}-{end_year}")
with col3:
    clear_button = st.button("üóëÔ∏è Clear", use_container_width=True)
    if clear_button:
        st.session_state.clear()
        st.rerun()

# Research execution
if start_button and query:
    st.session_state["last_query"] = query

    # Storytelling Progress Display
    progress_container = st.container()
    with progress_container:
        st.markdown("### üé¨ Watch Your Research Unfold")
        st.markdown("*AI agents are working together to discover insights for you...*")

        # Storytelling display for each agent
        story_container = st.container()
        
        scout_story = story_container.empty()
        analyst_story = story_container.empty()
        synthesizer_story = story_container.empty()
        coordinator_story = story_container.empty()
        
        # Initialize story placeholders
        scout_story.markdown("ü§ñ **Scout Agent**: Ready to search 7 databases...")
        analyst_story.markdown("")
        synthesizer_story.markdown("")
        coordinator_story.markdown("")

        # Overall progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        nim_indicator = st.empty()

    try:
        # Call agent orchestrator API
        status_text.text("üîÑ Initializing agents and NIMs...")
        progress_bar.progress(5)
        nim_indicator.info("üîç Checking Embedding NIM availability...")

        # Prepare API request with date filtering if enabled
        request_data = {"query": query, "max_papers": max_papers}

        if use_date_filter and start_year and end_year:
            request_data["start_year"] = int(start_year)
            request_data["end_year"] = int(end_year)
            request_data["prioritize_recent"] = True

        # Make API request with improved error handling (J-5: Enhanced Error Messages)
        try:
            response = requests.post(f"{api_url}/research", json=request_data, timeout=300)
        except requests.exceptions.Timeout:
            st.error("‚è±Ô∏è This query is taking longer than expected. Try a more specific question or reduce the number of papers.")
            st.info("üí° **Tip**: Narrow your query or try again in a moment. The system may be processing a complex synthesis.")
            st.stop()
        except requests.exceptions.ConnectionError:
            st.error("‚ö†Ô∏è Unable to connect to the research service. Please check if the API server is running.")
            st.info("üí° **Tip**: Make sure the API server is running at the configured endpoint.")
            st.stop()
        except Exception as e:
            logger.error(f"Unexpected error: {e}", exc_info=True)
            st.error("‚ùå Something went wrong. Our team has been notified.")
            st.info("üí° Please try again in a moment. If the problem persists, check the system logs.")
            st.stop()
        
        if response.status_code != 200:
            # User-friendly error messages
            try:
                error_data = response.json()
                error_msg = error_data.get("detail", error_data.get("error", "Unknown error"))
                
                if response.status_code == 429:
                    st.error("‚ö†Ô∏è Too many requests. Please wait a moment before trying again.")
                    st.info("üí° **Rate Limit**: The system is limiting requests to ensure fair usage. Please try again in a minute.")
                elif response.status_code == 503 or "circuit breaker" in str(error_msg).lower() or "circuitbreakeropen" in str(error_msg).lower():
                    st.error("‚ö†Ô∏è Our AI services are temporarily busy. Please try again in 1 minute.")
                    st.info("üí° **Service Unavailable**: The AI services are experiencing high load or are temporarily unavailable. The system will automatically retry shortly. This is a protective circuit breaker mechanism to prevent system overload.")
                elif response.status_code == 400:
                    st.error(f"‚ùå Invalid request: {error_msg}")
                    st.info("üí° **Tip**: Check your query format and parameters.")
                elif response.status_code == 500:
                    st.error("‚ùå An internal error occurred. Our team has been notified.")
                    st.info("üí° **Technical Error**: Please try again in a moment. If the problem persists, contact support.")
                else:
                    st.error(f"‚ùå Error ({response.status_code}): {error_msg}")
                    
                # Show error details in expander for debugging
                with st.expander("üîç Technical Details"):
                    st.json(error_data)
            except:
                st.error(f"‚ùå API Error: {response.status_code}")
                st.text(response.text)
        else:
            result = response.json()

            # Update progress indicators based on decisions
            decisions = result.get("decisions", [])

            # Determine which stages completed
            stages_completed = {
                "search": False,
                "analyze": False,
                "synthesize": False,
                "refine": False,
            }

            # Update storytelling display based on decisions
            papers_found = result.get("papers_analyzed", 0)
            contradictions_count = len(result.get("contradictions", []))
            themes_count = len(result.get("common_themes", []))
            gaps_count = len(result.get("research_gaps", []))
            
            for decision in decisions:
                agent = decision.get("agent", "")
                decision_type = decision.get("decision_type", "")

                if agent == "Scout":
                    stages_completed["search"] = True
                    scout_story.success(
                        f"‚ú® **Scout Agent**: Found {papers_found} relevant papers across 7 databases! "
                        f"Some are highly-cited breakthroughs."
                    )

                elif agent == "Analyst":
                    stages_completed["analyze"] = True
                    analyst_story.success(
                        f"üìä **Analyst Agent**: Deep-reading methodologies and extracting key findings from each paper..."
                    )

                elif agent == "Synthesizer":
                    stages_completed["synthesize"] = True
                    if "CONTRADICTION" in decision_type:
                        synthesizer_story.warning(
                            f"‚ö° **Discovery**: Found {contradictions_count} contradictions! "
                            f"Papers disagree on key findings‚Äîyou'd miss this manually."
                        )
                    elif "THEME" in decision_type or "GAP" in decision_type:
                        synthesizer_story.info(
                            f"üí° **Synthesizer Agent**: Identified {themes_count} major themes "
                            f"and {gaps_count} research gaps nobody else has spotted."
                        )

                elif agent == "Coordinator":
                    stages_completed["refine"] = True
                    coordinator_story.success(
                        f"‚úÖ **Coordinator Agent**: Synthesis is complete and ready! "
                        f"Quality check passed‚Äîall themes and contradictions are clearly explained."
                    )

            # Update progress using new progress tracker information
            progress_info = result.get("progress", {})
            overall_progress = progress_info.get("overall_progress", 0.0)
            current_stage = progress_info.get("current_stage", "complete")
            time_elapsed = progress_info.get("time_elapsed", 0)
            time_remaining = progress_info.get("time_remaining")
            nim_used = progress_info.get("nim_used")

            # Update progress bar with actual progress
            progress_bar.progress(overall_progress)

            # Update status text with time information
            if time_remaining is not None and time_remaining > 0:
                status_text.text(
                    f"‚è±Ô∏è Elapsed: {time_elapsed:.1f}s | Remaining: ~{time_remaining:.0f}s"
                )
            else:
                status_text.text(f"‚úÖ Complete! Total time: {time_elapsed:.1f} seconds")

            # Save to synthesis history
            try:
                from synthesis_history import get_synthesis_history
                history = get_synthesis_history()
                synthesis_id = history.add_synthesis(query, result)
                st.session_state["current_synthesis_id"] = synthesis_id
            except Exception as e:
                logger.warning(f"Failed to save synthesis history: {e}")
                synthesis_id = None

            # Display success message with shareable moment
            st.success(
                f"üéâ **Your research synthesis is ready!** "
                f"Completed in {time_elapsed:.1f} seconds. "
                f"Your advisor will love the transparency‚Äîsee exactly why agents made each decision."
            )
            
            # Shareable Discovery Moment
            contradictions_count = len(result.get("contradictions", []))
            gaps_count = len(result.get("research_gaps", []))
            themes_count = len(result.get("common_themes", []))
            
            if contradictions_count > 0 or gaps_count > 0:
                share_col1, share_col2 = st.columns([3, 1])
                with share_col1:
                    if contradictions_count > 0:
                        st.info(
                            f"üîç **Discovery**: Your agents found {contradictions_count} contradiction(s) in established research "
                            f"that you'd likely miss reading manually."
                        )
                    if gaps_count > 0:
                        st.info(
                            f"üí° **Gap Found**: Identified {gaps_count} research gap(s) for potential future work."
                        )
                with share_col2:
                    share_text = (
                        f"I just synthesized {papers_found} papers in {time_elapsed:.1f}s using AI agents! "
                        f"They found {contradictions_count} contradictions and {gaps_count} research gaps. "
                        f"Try it: [ResearchOps Agent]"
                    )
                    st.download_button(
                        "üì¢ Share Discovery",
                        data=share_text,
                        file_name="research_discovery.txt",
                        mime="text/plain",
                        help="Share your research discovery"
                    )

            # Baseline Comparison (J-3)
            st.markdown("## ‚ö° Efficiency Comparison")
            comp_col1, comp_col2 = st.columns(2)
            
            processing_time_min = result.get("processing_time_seconds", 0) / 60
            manual_time_hours = 8
            time_reduction = (1 - processing_time_min / (manual_time_hours * 60)) * 100
            
            with comp_col1:
                st.markdown("### üìù Manual Process")
                st.metric("Time Required", f"{manual_time_hours} hours")
                st.caption("‚ùå 10-15 papers typically analyzed\n‚ùå Variable quality and completeness\n‚ùå $200-400 cost per review")
            
            with comp_col2:
                st.markdown("### ü§ñ ResearchOps Agent")
                st.metric(
                    "Time Required", 
                    f"{processing_time_min:.1f} min",
                    delta=f"{time_reduction:.0f}% reduction",
                    delta_color="inverse"
                )
                st.caption(f"‚úÖ {result.get('papers_analyzed', 0)} papers analyzed\n‚úÖ Consistent quality\n‚úÖ ${0.15:.2f} cost per query")
            
            st.markdown("---")
            
            # Key Metrics
            st.markdown("## üìà Key Metrics")
            metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)

            with metric_col1:
                st.metric("Papers Analyzed", result.get("papers_analyzed", 0))
            with metric_col2:
                st.metric("Common Themes", len(result.get("common_themes", [])))
            with metric_col3:
                st.metric("Decisions Made", len(result.get("decisions", [])))
            with metric_col4:
                time_saved = manual_time_hours * 60 - processing_time_min
                st.metric("Time Saved", f"{time_saved:.1f} min", delta="97% reduction")

            st.markdown("---")
            
            # Cost Dashboard (J-4) - Show after results are available
            st.markdown("## üí∞ Real-Time Cost Dashboard")
            
            # Calculate estimated costs based on actual usage
            decisions = result.get("decisions", [])
            reasoning_requests = len([d for d in decisions if "Reasoning" in str(d.get("nim_used", ""))])
            embedding_requests = len([d for d in decisions if "Embedding" in str(d.get("nim_used", ""))])
            
            # Estimated costs per request (these would be actual costs in production)
            reasoning_cost_per_request = 0.0001  # $0.0001 per reasoning request
            embedding_cost_per_request = 0.00001  # $0.00001 per embedding request
            infra_cost_per_query = 0.05  # Infrastructure overhead
            
            reasoning_cost = reasoning_requests * reasoning_cost_per_request
            embedding_cost = embedding_requests * embedding_cost_per_request
            total_cost = reasoning_cost + embedding_cost + infra_cost_per_query
            
            cost_col1, cost_col2 = st.columns([1, 2])
            with cost_col1:
                st.metric("Query Cost", f"${total_cost:.3f}")
            with cost_col2:
                st.caption(f"""
                üí∞ **Cost Breakdown**
                - Reasoning NIM: ${reasoning_cost:.4f} ({reasoning_requests} requests)
                - Embedding NIM: ${embedding_cost:.4f} ({embedding_requests} requests)
                - Infrastructure: ${infra_cost_per_query:.3f}
                
                **Cost Efficiency**: ${0.15 - total_cost:.3f} savings vs manual review (${200 - total_cost:.2f} vs typical ${200})
                """)
            
            st.markdown("---")

            # Agent Decisions Section - Simplified (Show only key decisions)
            st.markdown("## üéØ How Agents Made Decisions")
            st.markdown("*See exactly why agents made each decision - full transparency, no black box*")

            decisions = result.get("decisions", [])

            if decisions:
                # Identify key decisions (most impactful)
                key_decision_types = [
                    "RELEVANCE_FILTERING",
                    "PAPER_SELECTION",
                    "CONTRADICTION_ANALYSIS",
                    "THEME_IDENTIFICATION",
                    "GAP_IDENTIFICATION",
                    "SYNTHESIS_QUALITY"
                ]
                
                key_decisions = [
                    d for d in decisions 
                    if any(kdt in d.get("decision_type", "") for kdt in key_decision_types)
                ][:5]  # Max 5 key decisions
                
                other_decisions = [d for d in decisions if d not in key_decisions]
                
                # Show key decisions prominently
                if key_decisions:
                    st.markdown("### üîç Key Decisions (3-5 Most Important)")
                    for i, decision in enumerate(key_decisions):
                        agent_emoji = {
                            "Scout": "üîç",
                            "Analyst": "üìä",
                            "Synthesizer": "üß©",
                            "Coordinator": "üéØ",
                        }.get(decision["agent"], "ü§ñ")

                        agent_class = f"agent-{decision['agent'].lower()}"

                        nim_badge = ""
                        if decision.get("nim_used"):
                            if "Reasoning" in decision["nim_used"]:
                                nim_badge = '<span class="nim-badge nim-reasoning">üß† Reasoning NIM</span>'
                            elif "Embedding" in decision["nim_used"]:
                                nim_badge = '<span class="nim-badge nim-embedding">üîç Embedding NIM</span>'

                        # Generate ARIA-friendly attributes
                        aria_label = (
                            f"{decision['agent']} decision: {decision['decision_type']}"
                        )
                        decision_id = f"decision-{i}-{decision['agent']}"

                        # Simplified decision display - researcher-friendly
                        decision_summary = decision.get("decision", "")
                        reasoning_simple = decision.get("reasoning", "")
                        
                        # Make reasoning more readable
                        if len(reasoning_simple) > 200:
                            reasoning_simple = reasoning_simple[:200] + "..."
                        
                        st.markdown(
                            f"""
                        <div 
                            class="decision-card {agent_class}" 
                            role="article"
                            aria-label="{aria_label}"
                            aria-describedby="{decision_id}"
                            tabindex="0"
                            id="{decision_id}"
                        >
                            <strong>{agent_emoji} {decision["agent"]} Agent</strong>{nim_badge}
                            <br><br>
                            <strong style="color: #1565C0; font-size: 1.1em;">{decision_summary}</strong>
                            <br>
                            <small style="color: #616161;">{reasoning_simple}</small>
                        </div>
                        """,
                            unsafe_allow_html=True,
                        )
                
                # Show other decisions in expander
                if other_decisions:
                    with st.expander(f"üìã View All {len(other_decisions)} Additional Decisions", expanded=False):
                        st.caption(f"Total decisions made: {len(decisions)}. Showing {len(key_decisions)} key decisions above.")
                        for i, decision in enumerate(other_decisions):
                            agent_emoji = {
                                "Scout": "üîç",
                                "Analyst": "üìä",
                                "Synthesizer": "üß©",
                                "Coordinator": "üéØ",
                            }.get(decision["agent"], "ü§ñ")
                            
                            st.markdown(f"**{agent_emoji} {decision['agent']}**: {decision.get('decision', 'N/A')}")
                            st.caption(decision.get('reasoning', '')[:150] + "...")
                
                # Create timeline view as alternative
                with st.expander("üìä Decision Timeline", expanded=False):
                    st.markdown("### ü§ñ Agent Decision Timeline")
                    st.markdown("*Visual representation of autonomous decision-making process*")
                    
                    for i, decision in enumerate(decisions):
                        agent_emoji = {
                            "Scout": "üîç",
                            "Analyst": "üìä",
                            "Synthesizer": "üß©",
                            "Coordinator": "üéØ",
                        }.get(decision["agent"], "ü§ñ")
                        
                        # Extract confidence if available in metadata
                        confidence = decision.get("metadata", {}).get("confidence", None)
                        confidence_text = f" (Confidence: {confidence:.0%})" if confidence else ""
                        
                        with st.expander(
                            f"Decision {i+1}: {decision.get('decision_type', 'Unknown')}{confidence_text}",
                            expanded=(i == 0)  # Expand first decision
                        ):
                            col1, col2 = st.columns([1, 3])
                            with col1:
                                st.markdown(f"**{agent_emoji} {decision['agent']}**")
                                if decision.get("nim_used"):
                                    st.caption(decision["nim_used"])
                            with col2:
                                st.markdown(f"**Action:** {decision['decision']}")
                                st.markdown(f"**Reasoning:** {decision['reasoning']}")
                                
                                # Show evidence if available
                                evidence = decision.get("metadata", {}).get("evidence", None)
                                if evidence:
                                    st.code(evidence, language="text")
                                
                                # Show timestamp
                                timestamp = decision.get("timestamp", "")
                                if timestamp:
                                    st.caption(f"‚è∞ {timestamp}")
                        
                        # Visual timeline connector (except for last item)
                        if i < len(decisions) - 1:
                            st.markdown("‚¨áÔ∏è")
            else:
                st.info("No decisions recorded for this synthesis.")

            # Feedback Loop (Short-Term Recommendation)
            st.markdown("---")
            st.markdown("## üí¨ Help Us Learn")
            st.markdown("*Your feedback helps our agents improve. Which decisions surprised you?*")
            
            feedback_col1, feedback_col2, feedback_col3 = st.columns(3)
            
            with feedback_col1:
                if st.button("‚úÖ Synthesis was helpful", use_container_width=True):
                    try:
                        from feedback import get_feedback_collector, FeedbackType
                        collector = get_feedback_collector()
                        synthesis_id = st.session_state.get("current_synthesis_id", "unknown")
                        collector.record_feedback(
                            synthesis_id=synthesis_id,
                            query=query,
                            feedback_type=FeedbackType.HELPFUL,
                            rating=5
                        )
                        st.success("Thank you! Your feedback helps improve the system.")
                        st.rerun()
                    except Exception as e:
                        st.warning(f"Feedback recording failed: {e}")
            
            with feedback_col2:
                if st.button("ü§î Somewhat helpful", use_container_width=True):
                    try:
                        from feedback import get_feedback_collector, FeedbackType
                        collector = get_feedback_collector()
                        synthesis_id = st.session_state.get("current_synthesis_id", "unknown")
                        collector.record_feedback(
                            synthesis_id=synthesis_id,
                            query=query,
                            feedback_type=FeedbackType.HELPFUL,
                            rating=3
                        )
                        st.info("Thanks for the feedback. How can we improve?")
                        st.rerun()
                    except Exception as e:
                        st.warning(f"Feedback recording failed: {e}")
            
            with feedback_col3:
                if st.button("‚ùå Not helpful", use_container_width=True):
                    feedback_text = st.text_area(
                        "What could we improve?",
                        placeholder="Tell us what went wrong...",
                        key="not_helpful_feedback"
                    )
                    if st.button("Submit Feedback", key="submit_not_helpful"):
                        try:
                            from feedback import get_feedback_collector, FeedbackType
                            collector = get_feedback_collector()
                            synthesis_id = st.session_state.get("current_synthesis_id", "unknown")
                            collector.record_feedback(
                                synthesis_id=synthesis_id,
                                query=query,
                                feedback_type=FeedbackType.NOT_HELPFUL,
                                rating=1,
                                comment=feedback_text
                            )
                            st.success("Thank you! Your feedback helps us learn and improve.")
                            st.rerun()
                        except Exception as e:
                            st.warning(f"Feedback recording failed: {e}")
            
            # Decision-specific feedback
            if key_decisions:
                st.markdown("### üéØ Which Decision Surprised You?")
                decision_feedback = st.selectbox(
                    "Select a decision that surprised you:",
                    [f"{d['agent']}: {d.get('decision', 'N/A')[:50]}..." for d in key_decisions],
                    key="surprising_decision",
                    help="Help us understand which agent decisions are most valuable"
                )
                if st.button("Record Surprising Decision", key="record_surprise"):
                    try:
                        from feedback import get_feedback_collector, FeedbackType
                        collector = get_feedback_collector()
                        synthesis_id = st.session_state.get("current_synthesis_id", "unknown")
                        selected_idx = [f"{d['agent']}: {d.get('decision', 'N/A')[:50]}..." for d in key_decisions].index(decision_feedback)
                        decision_id = key_decisions[selected_idx].get("decision_type", "unknown")
                        collector.record_feedback(
                            synthesis_id=synthesis_id,
                            query=query,
                            feedback_type=FeedbackType.DECISION_SURPRISING,
                            decision_id=decision_id
                        )
                        st.success("Thank you! We'll learn from this.")
                        st.rerun()
                    except Exception as e:
                        st.warning(f"Feedback recording failed: {e}")

            st.markdown("---")

            # Research Intelligence Platform Features (Long-Term)
            st.markdown("---")
            st.markdown("## üöÄ Research Intelligence Platform")
            st.markdown("*Beyond synthesis: hypothesis generation, trend prediction, and collaboration matching*")
            
            intel_tab1, intel_tab2, intel_tab3 = st.tabs([
                "üí° Hypotheses",
                "üìà Trends",
                "ü§ù Collaboration"
            ])
            
            with intel_tab1:
                try:
                    from research_intelligence import get_research_intelligence
                    intelligence = get_research_intelligence()
                    hypotheses = intelligence.generate_hypotheses(
                        result.get("common_themes", []),
                        result.get("research_gaps", []),
                        result.get("contradictions", [])
                    )
                    if hypotheses:
                        st.markdown("### üß™ Generated Research Hypotheses")
                        for i, hypothesis in enumerate(hypotheses, 1):
                            st.info(f"**Hypothesis {i}**: {hypothesis}")
                    else:
                        st.info("Generate hypotheses from your synthesis results")
                except Exception as e:
                    st.warning(f"Hypothesis generation unavailable: {e}")
            
            with intel_tab2:
                try:
                    from research_intelligence import get_research_intelligence
                    intelligence = get_research_intelligence()
                    trends = intelligence.predict_trends(
                        result.get("common_themes", []),
                        result.get("papers", []),
                        time_window_years=3
                    )
                    st.markdown("### üìä Predicted Research Trends")
                    st.write(f"**Direction**: {trends.get('predicted_direction', 'N/A')}")
                    st.write(f"**Confidence**: {trends.get('confidence', 0)*100:.0f}%")
                    st.write(f"**Time Horizon**: {trends.get('time_horizon', '3 years')}")
                    
                    # Collective Intelligence: Trending Gaps
                    try:
                        from research_intelligence import get_collective_intelligence
                        collective = get_collective_intelligence()
                        collective.record_usage(
                            query,
                            result.get("common_themes", []),
                            result.get("research_gaps", [])
                        )
                        trending_gaps = collective.identify_trending_gaps(5)
                        if trending_gaps:
                            st.markdown("### üî• Trending Research Gaps")
                            st.caption("Gaps discovered by multiple researchers:")
                            for gap in trending_gaps:
                                st.markdown(f"- {gap}")
                    except Exception as e:
                        pass  # Silent fail for collective intelligence
                except Exception as e:
                    st.warning(f"Trend prediction unavailable: {e}")
            
            with intel_tab3:
                try:
                    from research_intelligence import get_collective_intelligence
                    collective = get_collective_intelligence()
                    similar_researchers = collective.find_similar_researchers(
                        query,
                        result.get("common_themes", [])
                    )
                    
                    if similar_researchers:
                        st.markdown("### üë• Researchers Working on Similar Topics")
                        for researcher in similar_researchers:
                            with st.expander(f"Query: {researcher.get('query', 'N/A')[:50]}..."):
                                st.write(f"**Similarity**: {researcher.get('similarity', 0)*100:.0f}%")
                                st.write(f"**Themes**: {', '.join(researcher.get('themes', [])[:3])}")
                    else:
                        st.info("No similar researchers found yet. As more researchers use the platform, we'll identify collaboration opportunities.")
                except Exception as e:
                    st.warning(f"Collaboration matching unavailable: {e}")

            st.markdown("---")

            # Results Section
            st.markdown("## üìä What Your Agents Discovered")
            st.markdown("*Comprehensive findings from {0} papers analyzed across 7 databases*".format(result.get("papers_analyzed", 0)))

            # Common Themes
            themes = result.get("common_themes", [])
            themes_count = len(themes) if themes else 0
            with st.expander(f"üîç Common Themes ({themes_count} identified)", expanded=True):
                if themes:
                    for i, theme in enumerate(themes, 1):
                        st.markdown(
                            f"<strong style='color: #1565C0;'>{i}.</strong> <span style='color: #212121;'>{theme}</span>",
                            unsafe_allow_html=True,
                        )
                else:
                    st.info("No common themes identified.")

            # Contradictions
            with st.expander("‚ö° Contradictions Found"):
                contradictions = result.get("contradictions", [])
                if contradictions:
                    for i, contradiction in enumerate(contradictions, 1):
                        st.markdown(
                            f"""
                        <div style='color: #212121; line-height: 1.8;'>
                        <strong style='color: #1565C0; font-size: 1.1em;'>Contradiction {i}:</strong><br>
                        - <strong style='color: #000000;'>{contradiction.get("paper1", "Paper A")}</strong> says: <span style='color: #424242;'>{contradiction.get("claim1", "N/A")}</span><br>
                        - <strong style='color: #000000;'>{contradiction.get("paper2", "Paper B")}</strong> says: <span style='color: #424242;'>{contradiction.get("claim2", "N/A")}</span><br>
                        - <strong style='color: #D32F2F;'>Conflict:</strong> <span style='color: #616161;'>{contradiction.get("conflict", "N/A")}</span>
                        </div>
                        """,
                            unsafe_allow_html=True,
                        )
                else:
                    st.info("No contradictions found.")

            # Research Gaps
            with st.expander("üéØ Research Gaps Identified"):
                gaps = result.get("research_gaps", [])
                if gaps:
                    for gap in gaps:
                        st.markdown(
                            f"<div style='color: #212121; line-height: 1.6;'>‚Ä¢ <span style='color: #424242;'>{gap}</span></div>",
                            unsafe_allow_html=True,
                        )
                else:
                    st.info("No research gaps identified.")

            # Extract papers from result (needed for bias detection and citations)
            papers = result.get("papers", [])

            # Bias Detection Section
            if papers:
                st.markdown("---")
                st.markdown("## üîç Bias Analysis")

                try:
                    bias_analysis = detect_bias(papers)

                    col_bias1, col_bias2 = st.columns(2)

                    with col_bias1:
                        st.markdown("### üìä Analysis Results")

                        # Publication bias
                        pub_bias = bias_analysis.get("publication_bias", {})
                        if pub_bias.get("is_skewed"):
                            st.warning(
                                f"**Publication Bias:** {pub_bias.get('message', '')}"
                            )
                        else:
                            st.success(
                                f"**Publication Sources:** {pub_bias.get('message', 'Good diversity')}"
                            )

                        # Temporal bias
                        temp_bias = bias_analysis.get("temporal_bias", {})
                        if temp_bias.get("is_skewed"):
                            st.warning(
                                f"**Temporal Bias:** {temp_bias.get('message', '')}"
                            )
                        else:
                            st.success(
                                f"**Time Range:** {temp_bias.get('message', 'Good distribution')}"
                            )

                        # Venue bias
                        venue_bias = bias_analysis.get("venue_bias", {})
                        if venue_bias.get("is_skewed"):
                            st.warning(
                                f"**Venue Bias:** {venue_bias.get('message', '')}"
                            )
                        else:
                            st.success(
                                f"**Venues:** {venue_bias.get('message', 'Good diversity')}"
                            )

                    with col_bias2:
                        st.markdown("### üí° Recommendations")
                        recommendations = bias_analysis.get("recommendations", [])
                        if recommendations:
                            for rec in recommendations:
                                st.info(f"‚Ä¢ {rec}")
                        else:
                            st.success("No significant bias detected. Good diversity!")

                    # Overall assessment
                    overall = bias_analysis.get("overall_assessment", "")
                    if bias_analysis.get("warnings"):
                        st.markdown(f"**Overall Assessment:** ‚ö†Ô∏è {overall}")
                    else:
                        st.markdown(f"**Overall Assessment:** ‚úÖ {overall}")

                except Exception as e:
                    st.warning(f"Bias detection failed: {e}")

            # Quality Scores Section
            quality_scores = result.get("quality_scores", [])
            if quality_scores:
                st.markdown("---")
                st.markdown("## üìä Paper Quality Assessment")

                for qs in quality_scores:
                    paper_title = next(
                        (
                            p.get("title", "Unknown")
                            for p in result.get("papers", [])
                            if p.get("id") == qs.get("paper_id")
                        ),
                        "Unknown Paper",
                    )

                    with st.expander(
                        f"üìÑ {paper_title[:60]}... (Quality: {qs.get('overall_score', 0):.2f})"
                    ):
                        col1, col2 = st.columns(2)

                        with col1:
                            st.markdown("### Scores")
                            st.metric(
                                "Overall",
                                f"{qs.get('overall_score', 0):.2f}",
                                delta=f"{qs.get('confidence_level', 'medium').upper()}",
                            )
                            st.progress(qs.get("overall_score", 0))

                            st.markdown("**Breakdown:**")
                            st.write(
                                f"- Methodology: {qs.get('methodology_score', 0):.2f}"
                            )
                            st.write(
                                f"- Statistical: {qs.get('statistical_score', 0):.2f}"
                            )
                            st.write(
                                f"- Reproducibility: {qs.get('reproducibility_score', 0):.2f}"
                            )
                            st.write(f"- Venue: {qs.get('venue_score', 0):.2f}")
                            st.write(
                                f"- Sample Size: {qs.get('sample_size_score', 0):.2f}"
                            )

                        with col2:
                            strengths = qs.get("strengths", [])
                            issues = qs.get("issues", [])

                            if strengths:
                                st.markdown("### ‚úÖ Strengths")
                                for strength in strengths:
                                    st.success(f"‚úì {strength}")

                            if issues:
                                st.markdown("### ‚ö†Ô∏è Issues")
                                for issue in issues:
                                    st.warning(f"‚ö† {issue}")

            # Enhanced Extraction Data Section
            analyses = result.get("analyses", [])
            if analyses and any(a.get("metadata") for a in analyses):
                st.markdown("---")
                st.markdown("## üî¨ Enhanced Extraction Data")

                tab_stat, tab_exp, tab_comp, tab_repro = st.tabs(
                    [
                        "üìà Statistical Results",
                        "‚öôÔ∏è Experimental Setup",
                        "üìä Comparative Results",
                        "‚ôªÔ∏è Reproducibility",
                    ]
                )

                with tab_stat:
                    for analysis in analyses:
                        if analysis.get("metadata", {}).get("statistical_results"):
                            stats = analysis["metadata"]["statistical_results"]
                            st.markdown(
                                f"**Paper:** {analysis.get('paper_id', 'Unknown')}"
                            )
                            if stats.get("p_values"):
                                st.write(
                                    f"**P-values:** {', '.join(stats['p_values'])}"
                                )
                            if stats.get("effect_sizes"):
                                st.write(
                                    f"**Effect Sizes:** {', '.join(stats['effect_sizes'])}"
                                )
                            if stats.get("confidence_intervals"):
                                st.write(
                                    f"**Confidence Intervals:** {', '.join(stats['confidence_intervals'])}"
                                )
                            if stats.get("statistical_tests"):
                                st.write(
                                    f"**Tests:** {', '.join(stats['statistical_tests'])}"
                                )
                            st.markdown("---")

                with tab_exp:
                    for analysis in analyses:
                        if analysis.get("metadata", {}).get("experimental_setup"):
                            exp = analysis["metadata"]["experimental_setup"]
                            st.markdown(
                                f"**Paper:** {analysis.get('paper_id', 'Unknown')}"
                            )
                            if exp.get("datasets"):
                                st.write(f"**Datasets:** {', '.join(exp['datasets'])}")
                            if exp.get("hardware"):
                                st.write(f"**Hardware:** {exp['hardware']}")
                            if exp.get("hyperparameters"):
                                st.write(
                                    f"**Hyperparameters:** {', '.join(exp['hyperparameters'])}"
                                )
                            if exp.get("software_frameworks"):
                                st.write(
                                    f"**Frameworks:** {', '.join(exp['software_frameworks'])}"
                                )
                            st.markdown("---")

                with tab_comp:
                    for analysis in analyses:
                        if analysis.get("metadata", {}).get("comparative_results"):
                            comp = analysis["metadata"]["comparative_results"]
                            st.markdown(
                                f"**Paper:** {analysis.get('paper_id', 'Unknown')}"
                            )
                            if comp.get("baselines"):
                                st.write(
                                    f"**Baselines:** {', '.join(comp['baselines'])}"
                                )
                            if comp.get("benchmarks"):
                                st.write(
                                    f"**Benchmarks:** {', '.join(comp['benchmarks'])}"
                                )
                            if comp.get("improvements"):
                                st.write(
                                    f"**Improvements:** {', '.join(comp['improvements'])}"
                                )
                            st.markdown("---")

                with tab_repro:
                    for analysis in analyses:
                        if analysis.get("metadata", {}).get("reproducibility"):
                            repro = analysis["metadata"]["reproducibility"]
                            st.markdown(
                                f"**Paper:** {analysis.get('paper_id', 'Unknown')}"
                            )
                            st.write(
                                f"**Code Available:** {'‚úÖ Yes' if repro.get('code_available') else '‚ùå No'}"
                            )
                            st.write(
                                f"**Data Available:** {'‚úÖ Yes' if repro.get('data_available') else '‚ùå No'}"
                            )
                            if repro.get("repository_url"):
                                st.write(f"**Repository:** {repro['repository_url']}")
                            st.markdown("---")

            # Citation Styles Section
            # Note: papers already extracted above for bias detection
            if papers:
                st.markdown("---")
                st.markdown("### üìù Citations")

                citation_style = st.selectbox(
                    "Citation Style:",
                    ["APA", "MLA", "Chicago", "IEEE", "Nature"],
                    help="Select citation format",
                )

                citations = format_citations(papers, style=citation_style.lower())

                with st.expander(f"View {citation_style} Citations", expanded=False):
                    for i, citation in enumerate(citations, 1):
                        st.text(f"{i}. {citation}")

                # Download citations
                st.download_button(
                    label=f"üì• Download {citation_style} Citations",
                    data="\n\n".join([f"{i}. {c}" for i, c in enumerate(citations, 1)]),
                    file_name=f"citations_{citation_style.lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    help=f"Download citations in {citation_style} format",
                )

            # Download options with multiple formats
            st.markdown("---")
            st.markdown("### üì• Export Results")

            col1, col2, col3, col4, col5, col6, col7, col8 = st.columns(8)

            with col1:
                st.download_button(
                    label="üì• JSON",
                    data=json.dumps(result, indent=2),
                    file_name=f"research_synthesis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True,
                )

            with col2:
                # Create markdown report
                markdown_report = f"""# Research Synthesis Report

**Query:** {query}
**Date:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Papers Analyzed:** {result.get("papers_analyzed", 0)}

## Common Themes
{chr(10).join([f"{i}. {theme}" for i, theme in enumerate(result.get("common_themes", []), 1)])}

## Research Gaps
{chr(10).join([f"- {gap}" for gap in result.get("research_gaps", [])])}

## Autonomous Decisions Made
{chr(10).join([f"- **{d['agent']}**: {d['decision']}" for d in result.get("decisions", [])])}
"""
                st.download_button(
                    label="üìÑ Markdown",
                    data=markdown_report,
                    file_name=f"research_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    mime="text/markdown",
                    use_container_width=True,
                )

            with col3:
                # Generate BibTeX export
                papers = result.get("papers", [])
                if papers:
                    try:
                        bibtex_content = generate_bibtex(papers)
                        st.download_button(
                            label="üìö BibTeX",
                            data=bibtex_content,
                            file_name=f"references_{datetime.now().strftime('%Y%m%d_%H%M%S')}.bib",
                            mime="text/plain",
                            use_container_width=True,
                            help="Import into Zotero, Mendeley, or EndNote",
                        )
                    except Exception as e:
                        st.error(f"Error generating BibTeX: {e}")
                else:
                    st.button(
                        label="üìö BibTeX",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )

            with col4:
                # Generate LaTeX document
                if papers:
                    try:
                        latex_content = generate_latex_document(
                            query=query,
                            papers=papers,
                            themes=result.get("common_themes", []),
                            gaps=result.get("research_gaps", []),
                            contradictions=result.get("contradictions", []),
                            date=datetime.now().strftime("%B %d, %Y"),
                        )
                        st.download_button(
                            label="üìù LaTeX",
                            data=latex_content,
                            file_name=f"literature_review_{datetime.now().strftime('%Y%m%d_%H%M%S')}.tex",
                            mime="text/plain",
                            use_container_width=True,
                            help="Complete LaTeX document ready to compile",
                        )
                    except Exception as e:
                        st.error(f"Error generating LaTeX: {e}")
                else:
                    st.button(
                        label="üìù LaTeX",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )

            with col5:
                # Generate Word document export
                if papers:
                    try:
                        word_doc = generate_word_document(
                            query=query,
                            papers=papers,
                            themes=result.get("common_themes", []),
                            gaps=result.get("research_gaps", []),
                            contradictions=result.get("contradictions", []),
                        )
                        st.download_button(
                            label="üìÑ Word",
                            data=word_doc,
                            file_name=f"literature_review_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            use_container_width=True,
                            help="Microsoft Word document (.docx)",
                        )
                    except ImportError:
                        st.button(
                            label="üìÑ Word",
                            disabled=True,
                            use_container_width=True,
                            help="Install python-docx: pip install python-docx",
                        )
                    except Exception as e:
                        st.error(f"Error generating Word: {e}")
                else:
                    st.button(
                        label="üìÑ Word",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )

            with col6:
                # Generate PDF document export
                if papers:
                    try:
                        pdf_doc = generate_pdf_document(
                            query=query,
                            papers=papers,
                            themes=result.get("common_themes", []),
                            gaps=result.get("research_gaps", []),
                            contradictions=result.get("contradictions", []),
                        )
                        st.download_button(
                            label="üìï PDF",
                            data=pdf_doc,
                            file_name=f"literature_review_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                            mime="application/pdf",
                            use_container_width=True,
                            help="PDF document",
                        )
                    except ImportError:
                        st.button(
                            label="üìï PDF",
                            disabled=True,
                            use_container_width=True,
                            help="Install reportlab: pip install reportlab",
                        )
                    except Exception as e:
                        st.error(f"Error generating PDF: {e}")
                else:
                    st.button(
                        label="üìï PDF",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )

            # Add CSV, Excel, EndNote, HTML, XML, JSON-LD exports on second row
            st.markdown("<br>", unsafe_allow_html=True)
            col_csv, col_excel, col_endnote, col_html = st.columns(4)
            
            # Third row for advanced formats
            st.markdown("<br>", unsafe_allow_html=True)
            st.markdown("#### üî¨ Advanced Export Formats")
            col_xml, col_jsonld, col_html_enh, col_placeholder = st.columns(4)

            with col_csv:
                # Generate CSV export
                if papers:
                    try:
                        csv_content = generate_csv_export(result)
                        st.download_button(
                            label="üìä CSV",
                            data=csv_content,
                            file_name=f"research_synthesis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            use_container_width=True,
                            help="CSV format for spreadsheet analysis",
                        )
                    except Exception as e:
                        st.error(f"Error generating CSV: {e}")
                else:
                    st.button(
                        label="üìä CSV",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )

            with col_excel:
                # Generate Excel export
                if papers:
                    try:
                        excel_doc = generate_excel_export(result)
                        st.download_button(
                            label="üìó Excel",
                            data=excel_doc,
                            file_name=f"research_synthesis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True,
                            help="Excel format (.xlsx) for quantitative analysis",
                        )
                    except ImportError:
                        st.button(
                            label="üìó Excel",
                            disabled=True,
                            use_container_width=True,
                            help="Install openpyxl: pip install openpyxl",
                        )
                    except Exception as e:
                        st.error(f"Error generating Excel: {e}")
                else:
                    st.button(
                        label="üìó Excel",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )

            with col_endnote:
                # Generate EndNote export
                if papers:
                    try:
                        endnote_content = generate_endnote_export(papers)
                        st.download_button(
                            label="üìë EndNote",
                            data=endnote_content,
                            file_name=f"references_{datetime.now().strftime('%Y%m%d_%H%M%S')}.enw",
                            mime="text/plain",
                            use_container_width=True,
                            help="EndNote format (.enw) for citation management",
                        )
                    except Exception as e:
                        st.error(f"Error generating EndNote: {e}")
                else:
                    st.button(
                        label="üìë EndNote",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )

            with col_html:
                # Generate interactive HTML report
                if papers:
                    try:
                        html_content = generate_interactive_html_report(
                            query=query, result=result, papers=papers
                        )
                        st.download_button(
                            label="üåê HTML",
                            data=html_content,
                            file_name=f"research_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                            mime="text/html",
                            use_container_width=True,
                            help="Interactive HTML report with visualizations",
                        )
                    except Exception as e:
                        st.error(f"Error generating HTML: {e}")
                else:
                    st.button(
                        label="üåê HTML",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )
            
            # Advanced export formats
            with col_xml:
                # Generate XML export
                if papers:
                    try:
                        xml_content = generate_xml_export(result, papers)
                        st.download_button(
                            label="üìÑ XML",
                            data=xml_content,
                            file_name=f"research_synthesis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xml",
                            mime="application/xml",
                            use_container_width=True,
                            help="XML format for structured data exchange",
                        )
                    except Exception as e:
                        st.error(f"Error generating XML: {e}")
                else:
                    st.button(
                        label="üìÑ XML",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )
            
            with col_jsonld:
                # Generate JSON-LD export
                if papers:
                    try:
                        jsonld_content = generate_json_ld_export(result, papers)
                        st.download_button(
                            label="üîó JSON-LD",
                            data=jsonld_content,
                            file_name=f"research_synthesis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonld",
                            mime="application/ld+json",
                            use_container_width=True,
                            help="JSON-LD format (Schema.org compatible) for semantic web",
                        )
                    except Exception as e:
                        st.error(f"Error generating JSON-LD: {e}")
                else:
                    st.button(
                        label="üîó JSON-LD",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )
            
            with col_html_enh:
                # Generate enhanced HTML report
                if papers:
                    try:
                        html_enhanced = generate_enhanced_interactive_html_report(
                            query=query, result=result, papers=papers
                        )
                        st.download_button(
                            label="‚ú® Enhanced HTML",
                            data=html_enhanced,
                            file_name=f"research_report_enhanced_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                            mime="text/html",
                            use_container_width=True,
                            help="Enhanced interactive HTML with theme network, dark mode, and export",
                        )
                    except Exception as e:
                        st.error(f"Error generating enhanced HTML: {e}")
                else:
                    st.button(
                        label="‚ú® Enhanced HTML",
                        disabled=True,
                        use_container_width=True,
                        help="No papers available for export",
                    )

    except requests.exceptions.Timeout:
        progress_bar.progress(0)
        status_text.empty()
        st.error("‚ùå Request timeout. The research is taking longer than expected.")
        st.info("Try reducing the number of papers or simplifying the query.")

    except requests.exceptions.ConnectionError:
        progress_bar.progress(0)
        status_text.empty()
        st.error(f"‚ùå Cannot connect to API at {api_url}")
        st.info("""
        **Troubleshooting:**
        1. Verify the agent orchestrator is running
        2. Check the API URL in the sidebar
        3. Ensure NIMs are deployed and accessible
        """)

    except Exception as e:
        progress_bar.progress(0)
        status_text.empty()
        st.error(f"‚ùå Error during research: {str(e)}")
        with st.expander("Error Details"):
            st.exception(e)

elif start_button:
    st.warning("‚ö†Ô∏è Please enter a research query first")

# Footer - Platform Positioning (Long-Term Recommendation)
st.markdown("---")
st.markdown(
    """
<div style='text-align: center; color: #424242;'>
    <small style='color: #424242;'>
    üîç <strong>Research Intelligence Platform</strong> - Not just a tool, a research partner<br>
    Synthesis ‚Ä¢ Hypothesis Generation ‚Ä¢ Trend Prediction ‚Ä¢ Collaboration Matching<br>
    Research-grade AI with full transparency ‚Ä¢ <a href="/docs" target="_blank" style='color: #1976D2; text-decoration: none; font-weight: 500;'>API Docs</a> ‚Ä¢ 
    <a href="#" style='color: #1976D2; text-decoration: none;'>Zotero/Mendeley Integration</a> (Coming Soon)
    </small>
</div>
""",
    unsafe_allow_html=True,
)

# Session state management
if "example_query" not in st.session_state:
    st.session_state["example_query"] = ""
