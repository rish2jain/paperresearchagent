"""
Export Format Utilities
Supports multiple export formats for research synthesis results
"""

from typing import List, Dict, Any, Optional
from datetime import datetime
import re
import io
import csv

# Optional dependencies for Word/PDF export
try:
    from docx import Document
    from docx.shared import Inches, Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False

try:
    from reportlab.lib.pagesizes import letter
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    HAS_REPORTLAB = True
except ImportError:
    HAS_REPORTLAB = False


def generate_bibtex(papers: List[Dict[str, Any]]) -> str:
    """
    Generate BibTeX citation entries for papers
    
    Args:
        papers: List of paper dictionaries with id, title, authors, url, etc.
    
    Returns:
        BibTeX formatted string
    """
    bibtex_entries = []
    
    for paper in papers:
        # Generate citation key from first author and year
        citation_key = _generate_citation_key(paper)
        
        # Determine entry type (default to @article)
        entry_type = paper.get('entry_type', 'article')
        
        # Format authors for BibTeX (Last, First format)
        authors = _format_authors_bibtex(paper.get('authors', []))
        
        # Extract year if available
        year = _extract_year(paper)
        
        # Build BibTeX entry
        entry = f"@{entry_type}{{{citation_key},\n"
        entry += f"  title = {{{_escape_bibtex(paper.get('title', 'Unknown'))}}},\n"
        
        if authors:
            entry += f"  author = {{{authors}}},\n"
        
        if year:
            entry += f"  year = {{{year}}},\n"
        
        # Add URL if available
        if paper.get('url'):
            entry += f"  url = {{{paper['url']}}},\n"
        
        # Add abstract if available
        if paper.get('abstract'):
            # Truncate long abstracts for BibTeX
            abstract = paper['abstract'][:500] + ('...' if len(paper['abstract']) > 500 else '')
            entry += f"  abstract = {{{_escape_bibtex(abstract)}}},\n"
        
        # Add identifier if available
        paper_id = paper.get('id', '')
        if paper_id.startswith('arxiv-'):
            arxiv_id = paper_id.replace('arxiv-', '')
            entry += f"  eprint = {{{arxiv_id}}},\n"
            entry += f"  archivePrefix = {{arXiv}},\n"
            entry += f"  primaryClass = {{cs.AI}},\n"  # Default, could be smarter
        elif paper_id.startswith('pubmed-'):
            pmid = paper_id.replace('pubmed-', '')
            entry += f"  pmid = {{{pmid}}},\n"
        
        # Add source information
        source = paper.get('source', '')
        if source:
            entry += f"  note = {{Retrieved from {source}}},\n"
        
        # Remove trailing comma and close
        entry = entry.rstrip(',\n') + "\n}"
        bibtex_entries.append(entry)
    
    return "\n\n".join(bibtex_entries)


def generate_latex_document(
    query: str,
    papers: List[Dict[str, Any]],
    themes: List[str],
    gaps: List[str],
    contradictions: List[Dict],
    date: Optional[str] = None
) -> str:
    """
    Generate a complete LaTeX document for literature review
    
    Args:
        query: Research query
        papers: List of analyzed papers
        themes: Common themes identified
        gaps: Research gaps
        contradictions: Contradictions found
        date: Optional date string
    
    Returns:
        Complete LaTeX document as string
    """
    if not date:
        date = datetime.now().strftime('%B %d, %Y')
    
    latex = r"""\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}

\title{Literature Review: """ + _escape_latex(query) + """}
\author{ResearchOps Agent}
\date{""" + date + """}

\begin{document}

\maketitle

\begin{abstract}
This literature review synthesizes research findings on """ + _escape_latex(query) + """. 
The review analyzed """ + str(len(papers)) + """ papers and identified """ + str(len(themes)) + """ 
common themes, """ + str(len(contradictions)) + """ contradictions, and """ + str(len(gaps)) + """ 
research gaps. Generated automatically using ResearchOps Agent.
\end{abstract}

\section{Introduction}
This review synthesizes the current state of research on """ + _escape_latex(query) + """.
The synthesis was generated by analyzing """ + str(len(papers)) + """ relevant papers 
from multiple academic sources.

\section{Common Themes}

"""
    
    for i, theme in enumerate(themes, 1):
        latex += f"\\subsection{{Theme {i}}}\n"
        latex += _escape_latex(theme) + "\n\n"
    
    if contradictions:
        latex += r"\section{Contradictions and Disagreements}" + "\n\n"
        for i, contradiction in enumerate(contradictions, 1):
            latex += f"\\subsection{{Contradiction {i}}}\n"
            paper1 = contradiction.get('paper1', 'Paper A')
            claim1 = contradiction.get('claim1', 'N/A')
            paper2 = contradiction.get('paper2', 'Paper B')
            claim2 = contradiction.get('claim2', 'N/A')
            conflict = contradiction.get('conflict', 'N/A')
            
            latex += f"\\textbf{{{_escape_latex(paper1)}}} reports: {_escape_latex(claim1)}\n\n"
            latex += f"\\textbf{{{_escape_latex(paper2)}}} reports: {_escape_latex(claim2)}\n\n"
            latex += f"\\textit{{Conflict:}} {_escape_latex(conflict)}\n\n"
    
    if gaps:
        latex += r"\section{Research Gaps}" + "\n\n"
        latex += r"\begin{itemize}" + "\n"
        for gap in gaps:
            latex += f"\\item {_escape_latex(gap)}\n"
        latex += r"\end{itemize}" + "\n\n"
    
    latex += r"\section{References}" + "\n\n"
    latex += r"\bibliographystyle{plainnat}" + "\n"
    latex += r"\bibliography{references}" + "\n"
    
    latex += r"\end{document}"
    
    return latex


def _generate_citation_key(paper: Dict[str, Any]) -> str:
    """Generate a unique citation key for BibTeX"""
    authors = paper.get('authors', [])
    year = _extract_year(paper)
    
    if authors:
        # Use first author's last name
        first_author = authors[0]
        last_name = first_author.split()[-1] if ' ' in first_author else first_author
        last_name = re.sub(r'[^a-zA-Z]', '', last_name).lower()
        
        if year:
            citation_key = f"{last_name}{year}"
        else:
            citation_key = f"{last_name}{datetime.now().year}"
    else:
        # Fallback to paper ID
        citation_key = paper.get('id', 'unknown').replace('-', '').replace('_', '')
    
    # Ensure uniqueness by appending number if needed
    # This is simplified - in production, track used keys
    return citation_key[:20]  # BibTeX keys should be reasonable length


def _format_authors_bibtex(authors: List[str]) -> str:
    """Format author list for BibTeX (Last, First format)"""
    if not authors:
        return ""
    
    formatted_authors = []
    for author in authors:
        if not author:
            continue
        
        # Handle "First Last" format
        if ' ' in author:
            parts = author.split()
            if len(parts) >= 2:
                last = parts[-1]
                first = ' '.join(parts[:-1])
                formatted_authors.append(f"{last}, {first}")
            else:
                formatted_authors.append(author)
        else:
            # Single name - assume last name
            formatted_authors.append(author)
    
    return " and ".join(formatted_authors)


def _extract_year(paper: Dict[str, Any]) -> Optional[str]:
    """Extract publication year from paper"""
    # Try different fields
    if 'published_date' in paper:
        date_str = str(paper['published_date'])
        # Try to extract year from date string
        year_match = re.search(r'\b(19|20)\d{2}\b', date_str)
        if year_match:
            return year_match.group(0)
    
    if 'year' in paper:
        return str(paper['year'])
    
    # Try to extract from paper ID (e.g., arxiv-2024.00123)
    paper_id = paper.get('id', '')
    year_match = re.search(r'(19|20)\d{2}', paper_id)
    if year_match:
        return year_match.group(0)
    
    return None


def _escape_bibtex(text: str) -> str:
    """Escape special characters for BibTeX"""
    # BibTeX special characters: { } \ ~ ^
    text = text.replace('\\', '{\\textbackslash}')
    text = text.replace('{', '\\{')
    text = text.replace('}', '\\}')
    text = text.replace('~', '{\\textasciitilde}')
    text = text.replace('^', '{\\textasciicircum}')
    text = text.replace('&', '\\&')
    text = text.replace('%', '\\%')
    text = text.replace('$', '\\$')
    text = text.replace('#', '\\#')
    text = text.replace('_', '\\_')
    
    # Remove or replace special Unicode characters
    text = text.encode('ascii', 'ignore').decode('ascii')
    
    return text


def _escape_latex(text: str) -> str:
    """Escape special characters for LaTeX"""
    # LaTeX special characters
    special_chars = {
        '&': r'\&',
        '%': r'\%',
        '$': r'\$',
        '#': r'\#',
        '^': r'\^{}',
        '_': r'\_',
        '{': r'\{',
        '}': r'\}',
        '~': r'\textasciitilde{}',
        '\\': r'\textbackslash{}'
    }
    
    for char, escape in special_chars.items():
        text = text.replace(char, escape)
    
    return text


def generate_word_document(
    query: str,
    papers: List[Dict[str, Any]],
    themes: List[str],
    gaps: List[str],
    contradictions: List[Dict]
) -> Optional[io.BytesIO]:
    """
    Generate a Word document (.docx) for literature review.
    Requires 'python-docx' to be installed.
    
    Args:
        query: Research query
        papers: List of analyzed papers
        themes: Common themes identified
        gaps: Research gaps
        contradictions: Contradictions found
    
    Returns:
        BytesIO object containing the Word document, or None if docx not available
    """
    if not HAS_DOCX:
        raise ImportError("python-docx is not installed. Please install it with 'pip install python-docx'")
    
    # Create document
    doc = Document()
    
    # Add title
    title = doc.add_heading(f'Literature Review: {query}', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # Add metadata
    doc.add_paragraph(f'Generated by ResearchOps Agent')
    doc.add_paragraph(f'Date: {datetime.now().strftime("%B %d, %Y")}')
    doc.add_paragraph(f'Papers Analyzed: {len(papers)}')
    
    # Add abstract
    doc.add_heading('Abstract', level=1)
    abstract_text = (
        f"This literature review synthesizes research findings on {query}. "
        f"The review analyzed {len(papers)} papers and identified {len(themes)} "
        f"common themes, {len(contradictions)} contradictions, and {len(gaps)} "
        f"research gaps. Generated automatically using ResearchOps Agent."
    )
    doc.add_paragraph(abstract_text)
    
    # Add introduction
    doc.add_heading('Introduction', level=1)
    intro_text = (
        f"This review synthesizes the current state of research on {query}. "
        f"The synthesis was generated by analyzing {len(papers)} relevant papers "
        f"from multiple academic sources."
    )
    doc.add_paragraph(intro_text)
    
    # Add common themes
    doc.add_heading('Common Themes', level=1)
    for i, theme in enumerate(themes, 1):
        doc.add_heading(f'Theme {i}', level=2)
        doc.add_paragraph(theme)
    
    # Add contradictions
    if contradictions:
        doc.add_heading('Contradictions and Disagreements', level=1)
        for i, contradiction in enumerate(contradictions, 1):
            doc.add_heading(f'Contradiction {i}', level=2)
            paper1 = contradiction.get('paper1', 'Paper A')
            claim1 = contradiction.get('claim1', 'N/A')
            paper2 = contradiction.get('paper2', 'Paper B')
            claim2 = contradiction.get('claim2', 'N/A')
            conflict = contradiction.get('conflict', 'N/A')
            
            doc.add_paragraph(f'Paper 1 ({paper1}) reports: {claim1}')
            doc.add_paragraph(f'Paper 2 ({paper2}) reports: {claim2}')
            doc.add_paragraph(f'Conflict: {conflict}')
    
    # Add research gaps
    if gaps:
        doc.add_heading('Research Gaps', level=1)
        for gap in gaps:
            para = doc.add_paragraph(gap, style='List Bullet')
    
    # Add references
    doc.add_heading('References', level=1)
    for paper in papers:
        title_text = paper.get('title', 'Unknown Title')
        authors = ', '.join(paper.get('authors', []))
        year = _extract_year(paper) or 'Unknown Year'
        
        ref_text = f"{authors} ({year}). {title_text}."
        if paper.get('url'):
            ref_text += f" {paper['url']}"
        
        doc.add_paragraph(ref_text, style='List Bullet')
    
    # Save to BytesIO
    doc_bytes = io.BytesIO()
    doc.save(doc_bytes)
    doc_bytes.seek(0)
    
    return doc_bytes


def generate_pdf_document(
    query: str,
    papers: List[Dict[str, Any]],
    themes: List[str],
    gaps: List[str],
    contradictions: List[Dict]
) -> Optional[io.BytesIO]:
    """
    Generate a PDF document for literature review.
    Requires 'reportlab' to be installed.
    
    Args:
        query: Research query
        papers: List of analyzed papers
        themes: Common themes identified
        gaps: Research gaps
        contradictions: Contradictions found
    
    Returns:
        BytesIO object containing the PDF document, or None if reportlab not available
    """
    if not HAS_REPORTLAB:
        raise ImportError("reportlab is not installed. Please install it with 'pip install reportlab'")
    
    # Create BytesIO buffer
    buffer = io.BytesIO()
    
    # Create PDF document
    doc = SimpleDocTemplate(
        buffer,
        pagesize=letter,
        rightMargin=72,
        leftMargin=72,
        topMargin=72,
        bottomMargin=18
    )
    
    # Container for the 'Flowable' objects
    elements = []
    
    # Define styles
    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        textColor='#1a1a1a',
        spaceAfter=30,
        alignment=1  # Center
    )
    
    # Add title
    title = Paragraph(f'Literature Review: {_escape_latex(query)}', title_style)
    elements.append(title)
    elements.append(Spacer(1, 12))
    
    # Add metadata
    meta_text = (
        f'Generated by ResearchOps Agent<br/>'
        f'Date: {datetime.now().strftime("%B %d, %Y")}<br/>'
        f'Papers Analyzed: {len(papers)}'
    )
    elements.append(Paragraph(meta_text, styles['Normal']))
    elements.append(Spacer(1, 20))
    
    # Add abstract
    elements.append(Paragraph('<b>Abstract</b>', styles['Heading1']))
    abstract_text = (
        f"This literature review synthesizes research findings on {_escape_latex(query)}. "
        f"The review analyzed {len(papers)} papers and identified {len(themes)} "
        f"common themes, {len(contradictions)} contradictions, and {len(gaps)} "
        f"research gaps. Generated automatically using ResearchOps Agent."
    )
    elements.append(Paragraph(abstract_text, styles['Normal']))
    elements.append(Spacer(1, 20))
    
    # Add introduction
    elements.append(Paragraph('<b>Introduction</b>', styles['Heading1']))
    intro_text = (
        f"This review synthesizes the current state of research on {_escape_latex(query)}. "
        f"The synthesis was generated by analyzing {len(papers)} relevant papers "
        f"from multiple academic sources."
    )
    elements.append(Paragraph(intro_text, styles['Normal']))
    elements.append(Spacer(1, 20))
    
    # Add common themes
    elements.append(Paragraph('<b>Common Themes</b>', styles['Heading1']))
    for i, theme in enumerate(themes, 1):
        elements.append(Paragraph(f'<b>Theme {i}</b>', styles['Heading2']))
        elements.append(Paragraph(_escape_latex(theme), styles['Normal']))
        elements.append(Spacer(1, 12))
    
    # Add contradictions
    if contradictions:
        elements.append(Paragraph('<b>Contradictions and Disagreements</b>', styles['Heading1']))
        for i, contradiction in enumerate(contradictions, 1):
            elements.append(Paragraph(f'<b>Contradiction {i}</b>', styles['Heading2']))
            paper1 = contradiction.get('paper1', 'Paper A')
            claim1 = contradiction.get('claim1', 'N/A')
            paper2 = contradiction.get('paper2', 'Paper B')
            claim2 = contradiction.get('claim2', 'N/A')
            conflict = contradiction.get('conflict', 'N/A')
            
            elements.append(Paragraph(f'<b>Paper 1 ({_escape_latex(paper1)})</b> reports: {_escape_latex(claim1)}', styles['Normal']))
            elements.append(Paragraph(f'<b>Paper 2 ({_escape_latex(paper2)})</b> reports: {_escape_latex(claim2)}', styles['Normal']))
            elements.append(Paragraph(f'<i>Conflict:</i> {_escape_latex(conflict)}', styles['Normal']))
            elements.append(Spacer(1, 12))
    
    # Add research gaps
    if gaps:
        elements.append(Paragraph('<b>Research Gaps</b>', styles['Heading1']))
        for gap in gaps:
            elements.append(Paragraph(f'â€¢ {_escape_latex(gap)}', styles['Normal']))
            elements.append(Spacer(1, 6))
    
    # Add references
    elements.append(PageBreak())
    elements.append(Paragraph('<b>References</b>', styles['Heading1']))
    elements.append(Spacer(1, 12))
    
    for paper in papers:
        title_text = paper.get('title', 'Unknown Title')
        authors = ', '.join(paper.get('authors', []))
        year = _extract_year(paper) or 'Unknown Year'
        
        ref_text = f"<b>{_escape_latex(authors)}</b> ({year}). {_escape_latex(title_text)}."
        if paper.get('url'):
            ref_text += f" <link href=\"{paper['url']}\" color=\"blue\"><u>{_escape_latex(paper['url'])}</u></link>"
        
        elements.append(Paragraph(ref_text, styles['Normal']))
        elements.append(Spacer(1, 6))
    
    # Build PDF
    doc.build(elements)
    
    # Get the PDF data
    pdf_data = buffer.getvalue()
    buffer.close()
    
    # Create new BytesIO for return
    pdf_bytes = io.BytesIO(pdf_data)
    pdf_bytes.seek(0)
    
    return pdf_bytes


# Example usage
if __name__ == "__main__":
    sample_papers = [
        {
            "id": "arxiv-2024.001",
            "title": "Deep Learning for Medical Imaging",
            "authors": ["John Smith", "Jane Doe"],
            "abstract": "This paper explores...",
            "url": "https://arxiv.org/abs/2024.001",
            "published_date": "2024-01-15",
            "source": "arXiv"
        },
        {
            "id": "pubmed-12345",
            "title": "Clinical Applications of ML",
            "authors": ["Alice Johnson"],
            "abstract": "We investigate...",
            "url": "https://pubmed.ncbi.nlm.nih.gov/12345/",
            "published_date": "2023",
            "source": "PubMed"
        }
    ]
    
    bibtex = generate_bibtex(sample_papers)
    print("BibTeX Output:")
    print(bibtex)
    
    latex = generate_latex_document(
        query="machine learning for medical imaging",
        papers=sample_papers,
        themes=["Deep learning architectures", "Clinical validation"],
        gaps=["Multi-modal fusion", "Interpretability"],
        contradictions=[{"paper1": "Paper A", "claim1": "X", "paper2": "Paper B", "claim2": "Y", "conflict": "Different results"}]
    )
    print("\n\nLaTeX Document:")
    print(latex[:500] + "...")


def generate_csv_export(
    result: Dict[str, Any]
) -> str:
    """
    Generate CSV export for quantitative analysis
    
    Args:
        result: Research synthesis result dictionary
    
    Returns:
        CSV formatted string
    """
    import csv
    
    # Use StringIO to create CSV in memory
    output = io.StringIO()
    writer = csv.writer(output)
    
    # Header
    writer.writerow([
        "Paper ID", "Title", "Authors", "Source", "Year", 
        "URL", "Theme Matches", "Quality Score", "Methodology Score",
        "Statistical Score", "Reproducibility Score"
    ])
    
    # Papers data
    papers = result.get('papers', [])
    quality_scores = {qs.get('paper_id'): qs for qs in result.get('quality_scores', [])}
    themes = result.get('common_themes', [])
    
    for paper in papers:
        paper_id = paper.get('id', '')
        quality = quality_scores.get(paper_id, {})
        
        # Find matching themes
        title_lower = paper.get('title', '').lower()
        theme_matches = []
        for theme in themes:
            if any(word in title_lower for word in theme.lower().split()[:3]):  # Simple keyword matching
                theme_matches.append(theme[:50])  # Truncate long themes
        
        writer.writerow([
            paper_id,
            paper.get('title', '')[:100],  # Truncate for CSV readability
            '; '.join(paper.get('authors', []))[:200],
            paper.get('source', ''),
            _extract_year(paper) or '',
            paper.get('url', '')[:200],
            '; '.join(theme_matches[:3])[:200],  # Top 3 matching themes
            f"{quality.get('overall_score', 0):.2f}",
            f"{quality.get('methodology_score', 0):.2f}",
            f"{quality.get('statistical_score', 0):.2f}",
            f"{quality.get('reproducibility_score', 0):.2f}"
        ])
    
    return output.getvalue()


def generate_excel_export(
    result: Dict[str, Any]
) -> io.BytesIO:
    """
    Generate Excel (.xlsx) export for quantitative analysis
    Requires 'openpyxl' to be installed.
    
    Args:
        result: Research synthesis result dictionary
    
    Returns:
        BytesIO object containing the Excel file, or None if openpyxl not available
    """
    try:
        from openpyxl import Workbook
        from openpyxl.styles import Font, PatternFill, Alignment
        from openpyxl.utils import get_column_letter
    except ImportError:
        raise ImportError("openpyxl is not installed. Please install it with 'pip install openpyxl'")
    
    # Create workbook
    wb = Workbook()
    ws = wb.active
    ws.title = "Research Synthesis"
    
    # Header style
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_font = Font(color="FFFFFF", bold=True)
    
    # Headers
    headers = [
        "Paper ID", "Title", "Authors", "Source", "Year", 
        "URL", "Theme Matches", "Quality Score", "Methodology Score",
        "Statistical Score", "Reproducibility Score", "Venue Score", "Sample Size Score"
    ]
    
    for col_idx, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col_idx)
        cell.value = header
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = Alignment(horizontal="center", vertical="center")
    
    # Papers data
    papers = result.get('papers', [])
    quality_scores = {qs.get('paper_id'): qs for qs in result.get('quality_scores', [])}
    themes = result.get('common_themes', [])
    
    row = 2
    for paper in papers:
        paper_id = paper.get('id', '')
        quality = quality_scores.get(paper_id, {})
        
        # Find matching themes
        title_lower = paper.get('title', '').lower()
        theme_matches = []
        for theme in themes:
            if any(word in title_lower for word in theme.lower().split()[:3]):
                theme_matches.append(theme)
        
        ws.cell(row=row, column=1, value=paper_id)
        ws.cell(row=row, column=2, value=paper.get('title', ''))
        ws.cell(row=row, column=3, value=', '.join(paper.get('authors', [])))
        ws.cell(row=row, column=4, value=paper.get('source', ''))
        ws.cell(row=row, column=5, value=_extract_year(paper) or '')
        ws.cell(row=row, column=6, value=paper.get('url', ''))
        ws.cell(row=row, column=7, value='; '.join(theme_matches[:5]))
        ws.cell(row=row, column=8, value=quality.get('overall_score', 0))
        ws.cell(row=row, column=9, value=quality.get('methodology_score', 0))
        ws.cell(row=row, column=10, value=quality.get('statistical_score', 0))
        ws.cell(row=row, column=11, value=quality.get('reproducibility_score', 0))
        ws.cell(row=row, column=12, value=quality.get('venue_score', 0))
        ws.cell(row=row, column=13, value=quality.get('sample_size_score', 0))
        
        row += 1
    
    # Auto-adjust column widths
    for col_idx in range(1, len(headers) + 1):
        column_letter = get_column_letter(col_idx)
        max_length = 0
        for row in ws[column_letter]:
            try:
                if row.value:
                    max_length = max(max_length, len(str(row.value)))
            except:
                pass
        adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters
        ws.column_dimensions[column_letter].width = adjusted_width
    
    # Save to BytesIO
    excel_bytes = io.BytesIO()
    wb.save(excel_bytes)
    excel_bytes.seek(0)
    
    return excel_bytes

