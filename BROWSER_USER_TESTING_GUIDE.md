# Browser User Testing Execution Guide

**Date:** 2025-01-16  
**Application:** ResearchOps Agent Web UI  
**URL:** http://localhost:8501  
**API:** http://localhost:8080

## Prerequisites

- ‚úÖ Web UI running on http://localhost:8501
- ‚úÖ API running on http://localhost:8080
- ‚úÖ Browser MCP tools available
- ‚úÖ Screenshots directory created: `user_testing_screenshots/`

## Test Execution Plan

### Test 1: Page Load and Initial State

**Objective:** Verify the web UI loads correctly and all initial elements are visible.

**Steps:**
1. Navigate to `http://localhost:8501`
2. Wait for page to fully load
3. Take accessibility snapshot
4. Take screenshot: `test_1_page_load.png`
5. Verify:
   - Page title contains "Research Ops Agent" or "Agentic Scholar"
   - Sidebar is visible on the left
   - Query input field is present
   - Max papers slider is visible
   - Search/Start button is present
   - No JavaScript errors in console

**Expected Results:**
- ‚úÖ Page loads without errors
- ‚úÖ All UI elements are visible
- ‚úÖ Layout is correct

---

### Test 2: Query Input Form Interaction

**Objective:** Verify all form elements are functional.

**Steps:**
1. Locate query input field (use snapshot to find element reference)
2. Click on query input field
3. Type: "machine learning for medical imaging"
4. Locate max papers slider
5. Adjust slider to value 10
6. Locate date range picker (if present)
7. Check source selection checkboxes (if present)
8. Take screenshot: `test_2_form_interaction.png`

**Expected Results:**
- ‚úÖ Query input accepts text
- ‚úÖ Slider adjusts value
- ‚úÖ Date range picker works (if present)
- ‚úÖ Checkboxes toggle (if present)

---

### Test 3: Basic Search Query Execution

**Objective:** Execute a basic search and verify the workflow.

**Steps:**
1. Clear any existing query
2. Enter query: "machine learning"
3. Set max papers to 10
4. Click "Start Research" or "Search" button
5. Wait for progress indicator to appear
6. Monitor progress updates
7. Take screenshots at key stages:
   - `test_3_progress_searching.png` (Searching stage)
   - `test_3_progress_analyzing.png` (Analyzing stage)
   - `test_3_progress_synthesizing.png` (Synthesizing stage)
   - `test_3_results_complete.png` (Results displayed)

**Expected Results:**
- ‚úÖ Query submits successfully
- ‚úÖ Progress bar appears
- ‚úÖ Stages update: Searching ‚Üí Analyzing ‚Üí Synthesizing
- ‚úÖ Results appear within 2-5 minutes
- ‚úÖ No errors occur

---

### Test 4: Progress Tracking and Real-time Updates

**Objective:** Verify progress tracking works correctly.

**Steps:**
1. Start a new search query
2. Observe progress bar updates
3. Check stage indicators (Searching, Analyzing, Synthesizing)
4. Verify time estimates are shown
5. Check for NIM usage badges:
   - üü¶ Reasoning NIM badge
   - üü© Embedding NIM badge
6. Monitor decision log updates (if visible)
7. Take screenshot: `test_4_progress_tracking.png`

**Expected Results:**
- ‚úÖ Progress updates in real-time
- ‚úÖ Current stage is highlighted
- ‚úÖ Time estimates are displayed
- ‚úÖ NIM badges appear correctly
- ‚úÖ Decision log updates live (if visible)

---

### Test 5: Results Display and Paper Cards

**Objective:** Verify results are displayed correctly.

**Steps:**
1. Wait for search to complete
2. Verify papers are displayed in cards
3. Check each paper card shows:
   - Title
   - Authors
   - Abstract (or preview)
   - Source badge
4. Click to expand paper details (if expandable)
5. Verify abstract is fully visible when expanded
6. Check source attribution is correct
7. Take screenshot: `test_5_results_display.png`

**Expected Results:**
- ‚úÖ Papers displayed in cards
- ‚úÖ All required information is shown
- ‚úÖ Expandable sections work
- ‚úÖ Source badges are visible

---

### Test 6: Decision Log Display

**Objective:** Verify decision log shows agent decisions correctly.

**Steps:**
1. Locate decision log section
2. Expand decision log (if collapsed)
3. Verify agent decisions are shown:
   - Scout Agent decisions
   - Analyst Agent decisions
   - Synthesizer Agent decisions
   - Coordinator Agent decisions
4. Check NIM badges for each decision:
   - üü¶ Reasoning NIM badge
   - üü© Embedding NIM badge
   - üü¶üü© Both badges (if both used)
5. Verify decision reasoning text is displayed
6. Check timeline visualization (if present)
7. Take screenshot: `test_6_decision_log.png`

**Expected Results:**
- ‚úÖ Decision log is expandable
- ‚úÖ All 4 agents show decisions
- ‚úÖ NIM badges correctly identify which NIM was used
- ‚úÖ Decision reasoning is displayed
- ‚úÖ Timeline shows chronological order

---

### Test 7: Synthesis Display

**Objective:** Verify synthesis results are displayed correctly.

**Steps:**
1. Locate synthesis section
2. Verify themes are listed
3. Check contradictions section (if any)
4. Verify research gaps section
5. Check enhanced insights dashboard:
   - Field maturity score
   - Research opportunities
   - Consensus scores
   - Hot debates (if any)
6. Test expand/collapse functionality
7. Take screenshot: `test_7_synthesis_display.png`

**Expected Results:**
- ‚úÖ Synthesis section is visible
- ‚úÖ Themes are clearly listed
- ‚úÖ Contradictions are highlighted (if present)
- ‚úÖ Research gaps are identified
- ‚úÖ Enhanced insights dashboard shows metrics
- ‚úÖ Expand/collapse works smoothly

---

### Test 8: Export Functionality

**Objective:** Verify export options work correctly.

**Steps:**
1. Locate export dropdown/button
2. Click to open export options
3. Test JSON export:
   - Click JSON option
   - Verify download triggers
4. Test Markdown export:
   - Click Markdown option
   - Verify download triggers
5. Test BibTeX export:
   - Click BibTeX option
   - Verify download triggers
6. Take screenshot: `test_8_export_options.png`

**Expected Results:**
- ‚úÖ Export options are available
- ‚úÖ Downloads trigger successfully
- ‚úÖ All export formats work

---

### Test 9: Responsive Design Testing

**Objective:** Verify the UI adapts to different screen sizes.

**Steps:**
1. Resize browser to 375px width (mobile)
2. Take screenshot: `test_9_mobile_375px.png`
3. Verify layout adapts
4. Resize to 768px width (tablet)
5. Take screenshot: `test_9_tablet_768px.png`
6. Verify layout adapts
7. Resize to 1920px width (desktop)
8. Take screenshot: `test_9_desktop_1920px.png`
9. Verify layout adapts

**Expected Results:**
- ‚úÖ Layout adapts to mobile size
- ‚úÖ Layout adapts to tablet size
- ‚úÖ Layout adapts to desktop size
- ‚úÖ No horizontal scrolling
- ‚úÖ All elements remain accessible

---

### Test 10: Error Handling and Validation

**Objective:** Verify error handling works correctly.

**Steps:**
1. Submit empty query
2. Verify error message appears
3. Take screenshot: `test_10_empty_query_error.png`
4. Enter query with invalid date range (e.g., future dates)
5. Verify validation error
6. Test with special characters: `<script>alert('xss')</script>`
7. Verify sanitization (no XSS)
8. Take screenshot: `test_10_validation.png`

**Expected Results:**
- ‚úÖ Empty query shows error
- ‚úÖ Invalid inputs are validated
- ‚úÖ Error messages are clear
- ‚úÖ Special characters are sanitized
- ‚úÖ No crashes occur

---

## Browser MCP Tool Usage

### Navigation
```python
browser_navigate(url="http://localhost:8501")
```

### Taking Snapshots
```python
snapshot = browser_snapshot()
# Use snapshot to find element references
```

### Clicking Elements
```python
browser_click(
    element="query input field",
    ref="<element_ref_from_snapshot>"
)
```

### Typing Text
```python
browser_type(
    element="query input",
    ref="<element_ref>",
    text="machine learning"
)
```

### Taking Screenshots
```python
browser_take_screenshot(
    filename="test_1_page_load.png"
)
```

### Waiting
```python
browser_wait_for(text="Searching")
browser_wait_for(time=5)  # Wait 5 seconds
```

---

## Test Results Template

```markdown
## Test Results - [Date]

### Test 1: Page Load
- Status: ‚úÖ PASS / ‚ùå FAIL
- Screenshot: test_1_page_load.png
- Notes: [Any observations]

### Test 2: Query Input Form
- Status: ‚úÖ PASS / ‚ùå FAIL
- Screenshot: test_2_form_interaction.png
- Notes: [Any observations]

[... continue for all tests ...]

## Summary
- Total Tests: 10
- Passed: X
- Failed: Y
- Success Rate: Z%
```

---

## Next Steps

1. Execute each test scenario using browser MCP tools
2. Document results (PASS/FAIL) for each test
3. Capture screenshots at key interaction points
4. Generate final report with test results
5. Document any issues or bugs found

---

**Note:** If browser MCP tools are not working, these tests can be executed manually using a regular browser, following the same steps and taking screenshots manually.

